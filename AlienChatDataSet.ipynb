{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSet:\n",
    "    def __init__(self, df):\n",
    "        self.rawdata = df\n",
    "        self.data = np.stack(df[\"data\"]) if not df[\"data\"].empty else np.array([])\n",
    "        self.labels = np.stack(df[\"label\"]) if not df[\"label\"].empty else np.array([])\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self, vocabulary, sentence_length, validation_split=0.2, chunk_length=1):\n",
    "        self.train = None\n",
    "        self.validation = None\n",
    "        self.test = None\n",
    "        self.vocabulary = vocabulary\n",
    "        self.output_labels = len(vocabulary)\n",
    "        self.sentence_length = sentence_length\n",
    "        self.v_split = validation_split\n",
    "        self.chunk_length = chunk_length\n",
    "\n",
    "    def load_data(self, traincsv, testcsv, blow_training_data=0, patterns=False):\n",
    "        alltraindf = self.read_from_csv(traincsv, patterns=patterns)\n",
    "        if blow_training_data > 0:\n",
    "            alltraindf = pd.concat([alltraindf] * (blow_training_data + 1), ignore_index=True)\n",
    "            alltraindf = alltraindf.sample(frac=1).reset_index(drop=True)\n",
    "        alltestdf = self.read_from_csv(testcsv)\n",
    "        t_split = 1 - self.v_split\n",
    "        if t_split < 1 :\n",
    "            traindf, validationdf = np.split(alltraindf.sample(frac=1), [int(t_split * len(alltraindf))])\n",
    "        else : \n",
    "            traindf, validationdf = alltraindf.sample(frac=1), pd.DataFrame({'data' : [], 'label' : []})\n",
    "        self.train = SubSet(traindf)\n",
    "        self.validation = SubSet(validationdf)\n",
    "        self.test = SubSet(alltestdf)\n",
    "        return self\n",
    "\n",
    "    def read_from_csv(self, csv, patterns=False):\n",
    "        alldata = pd.read_csv(csv, names=[\"sentence\"])\n",
    "        if patterns :\n",
    "            alldata_half = alldata.copy()\n",
    "            alldata_half[\"sentence\"] = pd.DataFrame(alldata_half[\"sentence\"].apply(lambda x: x[:5]))\n",
    "            alldata = alldata.append(alldata_half, ignore_index=True)\n",
    "        alldata[['data', 'label']] = pd.DataFrame(alldata['sentence'].apply(self.split_sentence_ascii).tolist())\n",
    "        # alldata[\"data\"], alldata[\"label\"] = zip(*alldata[\"sentence\"].map(self.split_sentence_ascii))\n",
    "        alldata['data'] = alldata['data'].apply(np.array)\n",
    "        alldata[\"label\"] = alldata[\"label\"].apply(np.array)\n",
    "        # databycol = pd.DataFrame(alldata[\"data\"].to_numpy(), columns=[str(i) for i in range(8)])\n",
    "        # print(databycol)\n",
    "        return alldata\n",
    "\n",
    "    def split_sentence_ascii(self, sentence):\n",
    "        data = [self.get_binary(self.vocabulary[i], self.output_labels) for i in sentence[:-1]] + [np.zeros(self.output_labels) for i in\n",
    "                                                                           range(self.sentence_length - len(sentence))]\n",
    "        #         if SENTENCE_LENGTH - len(sentence) > 0:\n",
    "        #             traindata\n",
    "        data = np.array(data)\n",
    "        data = np.reshape(data, (data.shape[0] // self.chunk_length, self.chunk_length * data.shape[1]))\n",
    "        label = self.get_binary(self.vocabulary[sentence[-1]], self.output_labels)\n",
    "        return data, label\n",
    "\n",
    "    @staticmethod\n",
    "    def get_binary(index, length):\n",
    "        binary = np.zeros(length)\n",
    "        if index > -1 and index < length: binary[index] = 1\n",
    "        return binary\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '.'\n",
    "train_file = parent_dir+'/'+'data/train.csv'\n",
    "test_file = parent_dir+'/'+'data/answers.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"3\": 28, \"M\": 12, \"R\": 17, \"4\": 29, \"Z\": 25, \"G\": 6, \"D\": 3, \"J\": 9, \"T\": 19, \"N\": 13, \"5\": 30, \"H\": 7, \"O\": 14, \"Q\": 16, \"W\": 22, \"V\": 21, \"I\": 8, \"L\": 11, \"1\": 26, \"2\": 27, \"A\": 0, \"S\": 18, \"C\": 2, \"F\": 5, \"7\": 32, \"X\": 23, \"E\": 4, \"6\": 31, \"K\": 10, \"B\": 1, \"U\": 20, \"P\": 15, \"Y\": 24}'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCE_LENGTH = 9\n",
    "\n",
    "ALPHABET = [chr(i) for i in range(65, 91)]\n",
    "GRAMMAR_MAP = {}\n",
    "\n",
    "for c in ALPHABET :\n",
    "    GRAMMAR_MAP[c] = ord(c) - ord('A')\n",
    "\n",
    "for i in range(1, 7+1) :\n",
    "    GRAMMAR_MAP[str(i)] = GRAMMAR_MAP['Z'] + 1 + (ord(str(i)) - ord('1'))\n",
    "\n",
    "REVERSE_GRAMMAR_MAP = ['']*len(GRAMMAR_MAP)\n",
    "\n",
    "for char in GRAMMAR_MAP:\n",
    "    REVERSE_GRAMMAR_MAP[GRAMMAR_MAP[char]] = str(char)\n",
    "    \n",
    "CHUNK_LENGTH = 1\n",
    "\n",
    "json.dumps(GRAMMAR_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "alienchat = DataSet(GRAMMAR_MAP, SENTENCE_LENGTH, validation_split=0, chunk_length=CHUNK_LENGTH)\\\n",
    "            .load_data(train_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2543, 8, 33), (2543, 33), (0,), (0,), (379, 8, 33), (379, 33))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alienchat.train.data.shape, alienchat.train.labels.shape, \\\n",
    "alienchat.validation.data.shape, alienchat.validation.labels.shape, \\\n",
    "alienchat.test.data.shape, alienchat.test.labels.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
